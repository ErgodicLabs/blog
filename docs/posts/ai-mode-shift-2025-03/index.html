<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Every app will become an AI app, just not in the way that you think :: Ergodic Labs blog</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Yes, every app will become an AI app. But it won’t happen because every app adopts AI. It will happen because AI learns to be a power user of every app.
The shape of AI products is changing. The user experience is no longer defined by screens and buttons. Models are becoming the user interface.
Last cycle In the last cycle, AI products looked like AI Dungeon, Jasper.ai, and GitHub Copilot. These apps didn’t expose models directly. Instead, they embedded them behind carefully constructed prompts and application-specific logic. The prompts were fixed and put the models on rails.
" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="https://ergodiclabs.github.io/blog/posts/ai-mode-shift-2025-03/" />


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FTE60X8VDH"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FTE60X8VDH');
        }
      </script>



  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/code.min.4f0ccc8439f99bf7f7970298556b94011aabc1fcae743b6842fc3361a2da9ea3.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/fonts.min.5bb7ed13e1d00d8ff39ea84af26737007eb5051b157b86fc24487c94f3dc8bbe.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/main.min.15870410d15d02abd22fb5ef00996f65a00d04b3a7435e9f83831c7c2298de88.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/menu.min.3c17467ebeb3d38663dce68f71f519901124fa5cbb4519b2fb0667a21e9aca39.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/post.min.e6dddd258e64c83e05cec0cd49c05216742d42fc8ecbfbe6b67083412b609bd3.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/syntax.min.a0773cce9310cb6d8ed23e50f005448facf29a53001b57e038828daa466b25c0.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/terminal.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css">

  
  <link rel="stylesheet" href="https://ergodiclabs.github.io/blog/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">


<link rel="stylesheet" href="https://ergodiclabs.github.io/blog/terminal.css">




<link rel="shortcut icon" href="https://ergodiclabs.github.io/blog/favicon.png">
<link rel="apple-touch-icon" href="https://ergodiclabs.github.io/blog/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Every app will become an AI app, just not in the way that you think">
<meta property="og:description" content="Yes, every app will become an AI app. But it won’t happen because every app adopts AI. It will happen because AI learns to be a power user of every app.
The shape of AI products is changing. The user experience is no longer defined by screens and buttons. Models are becoming the user interface.
Last cycle In the last cycle, AI products looked like AI Dungeon, Jasper.ai, and GitHub Copilot. These apps didn’t expose models directly. Instead, they embedded them behind carefully constructed prompts and application-specific logic. The prompts were fixed and put the models on rails.
" />
<meta property="og:url" content="https://ergodiclabs.github.io/blog/posts/ai-mode-shift-2025-03/" />
<meta property="og:site_name" content="Ergodic Labs blog" />

  <meta property="og:image" content="https://ergodiclabs.github.io/blog/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">


  <meta property="article:published_time" content="2025-03-30 00:00:00 &#43;0000 UTC" />












</head>
<body>


<div class="container">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="https://ergodiclabs.github.io/blog/">
  <div class="logo">
    Ergodic Labs blog
  </div>
</a>

    </div>
    
    
  </div>
  
</header>


  <div class="content">
    
<article class="post">
  <h1 class="post-title">
    <a href="https://ergodiclabs.github.io/blog/posts/ai-mode-shift-2025-03/">Every app will become an AI app, just not in the way that you think</a>
  </h1>
  <div class="post-meta"><time class="post-date">2025-03-30</time><span class="post-author">moorkh</span></div>

  
    <span class="post-tags">
      
      #<a href="https://ergodiclabs.github.io/blog/tags/ai/">ai</a>&nbsp;
      
    </span>
  
  


  

  <div class="post-content"><div>
        <p>Yes, every app will become an AI app. But it won’t happen because every app adopts AI. It will happen because AI learns to be a power user of every app.</p>
<p>The shape of AI products is changing. The user experience is no longer defined by screens and buttons. Models are becoming the user interface.</p>
<h3 id="last-cycle">Last cycle<a href="#last-cycle" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>In the last cycle, AI products looked like AI Dungeon, Jasper.ai, and GitHub Copilot. These apps didn’t expose models directly. Instead, they embedded them behind carefully constructed prompts and application-specific logic. The prompts were fixed and put the models on rails.</p>
<p>Jasper is a particularly clear case. It was early to market and quickly captured attention as a productized application of LLMs for marketing and content creation. Its initial value came entirely from its prompt templates. As soon as users had access to a general-purpose interface like ChatGPT, Jasper&rsquo;s moat disappeared. Why would most users pay more for a separate app when ChatGPT did the same and more for cheaper?</p>
<p>AI Dungeon, Jasper, and Copilot share a common mode of using AI. The application controls the interface. The prompts are fixed. The model serves as an internal function and is not exposed directly to the user. These products were all highly influential when they were launched. Each helped define what it meant to build with LLMs. But they have all lost relevance now. They have been eclipsed by more general-purpose interfaces. AI Dungeon and Jasper have been displaced by ChatGPT. GitHub Copilot, once a breakout success, has been displaced by  model-centric developer tools like Cursor and Windsurf.</p>
<p>Cursor and Windsurf are shaped more like ChatGPT than GitHub Copilot. They place the model at the center of the user experience. For their users, the model is an active collaborator.</p>
<h3 id="agents">Agents<a href="#agents" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>This transition coincides with the rise of &ldquo;agents.&rdquo; At this point, the word “agent” is more an SEO keyword than a meaningful term. Anything with a loop, memory, or vector store is branded an agent regardless of its level of actual agency. Most popular agentic frameworks (like LangChain and AutoGPT) don’t represent a fundamentally new mode of using AI. They are frameworks for orchestration, static chains of prompts augmented with memory, retrievers, and tool calls. These systems execute goals in isolation and often remove the user from the loop too early. They simulate autonomy through recursive loops and prompt mutation. In practice this leads to brittle behavior, recursive failure, and drift from user intent. The hype has outpaced the utility.</p>
<p>Some frameworks try to simulate dynamic behavior through prompt rewriting or recursive planning. But this also makes the operation of agents less transparent. In the future, models will determine their own goals. They will modify their own internal representations, their own input tensors, even their own architectures. That future is coming but it is not here yet. Pretending that it is will not bring us success in the next cycle.</p>
<h3 id="next-cycle">Next cycle<a href="#next-cycle" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>In the near future, AI products will adopt a more interactive structure. Humans will provide high-level intent in real time, and the model will take autonomous action to realize it. Models will take these actions by making use of external tools. This pattern preserves clarity and control for users. Humans shape direction, models handle execution.</p>
<p>For now, it’s easier to keep the user in the loop and let the model handle execution, not purpose. For now, this is what people want. In the current human-AI power dynamic, this is the more palatable design.</p>
<p>In the next cycle, the model itself will become the primary user interface. Users will no longer begin their tasks inside applications. They will begin with ChatGPT, Claude, Grok. These centralized assistants will be where work is initiated, planned, and often completed. They will become the default surface through which users think and act.</p>
<p>Even when interacting with complex tools like Figma, Photoshop, or Notion, users increasingly want to delegate entire projects to their models. They don’t want the AI embedded in the app. They want the AI that they use every day to use the app on their behalf.</p>
<p>Jasper&rsquo;s fall from grace is again instructive. Its value wasn’t in doing something a model couldn’t do. It was obscuring the need for users to interact with the model directly. Once general-purpose interfaces became usable, its earlier position was no longer defensible. The same dynamic now threatens every application that assumes the AI should be embedded, not externalized.</p>
<h3 id="model-context-protocol">Model Context Protocol<a href="#model-context-protocol" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>This shift demands new infrastructure. Anthropic introduced it in November 2024 in the form of the Model Context Protocol (MCP).</p>
<p>MCP standardizes connections between AI models and external apps. The Model Context Protocol is inspired by the Language Server Protocol (LSP), which was instrumental in Visual Studio Code attaining dominance among code editors. MCP lets models invoke application capabilities through a standardized interface.</p>
<p>Today, in April 2025, MCP has been adopted by major platforms -- Anthropic, Cursor, and OpenAI. This signals strong industry momentum.</p>
<p>MCP servers already demonstrate significant value. For example,</p>
<ul>
<li>GitHub MCP servers let programmers seamlessly manage repositories and automate commits directly through AI models.</li>
<li>Blender MCP servers allow users to control 3D modeling tasks through simple AI prompts, dramatically simplifying complex graphical workflows.</li>
</ul>
<p>There are already products like smithery.ai which allow power users to add MCP servers to applications which support them.</p>
<p>This structural shift has deep implications for builders. The AI interface itself is becoming the primary product, while traditional applications transition to backend services. Builders will increasingly focus not on building full-stack applications but on creating surfaces easily addressable by AI models. The value of an application will hinge on how effectively it integrates with and enhances model-driven workflows, rather than direct user interactions alone.</p>
<h3 id="open-problems">Open problems<a href="#open-problems" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>As a builder, the most exciting part of all is how much there is left to figure out. These are just some of the open problems we need to solve to bring about the next cycle of AI products:</p>
<h4 id="i-can-open-source-llms-participate-in-the-next-cycle">I. Can open source LLMs participate in the next cycle?<a href="#i-can-open-source-llms-participate-in-the-next-cycle" class="hanchor" ariaLabel="Anchor">#</a> </h4>
<p>It is critical in the long-term that we have self-hostable implementations of AI models. Otherwise, we will be forced to give corporations like Anthropic and OpenAI access to our most sensitive data with absolutely no alternatives.</p>
<p>This will probably need the cooperation of products like Cursor, Manus.ai, and their peers. These are products which control a lot of the current mindshare but which rely on the big model providers to drive their functionality. The size of their user bases makes them fantastic distribution channels for open source models.</p>
<h4 id="ii-how-can-remote-access-to-mcp-tools-scale">II. How can remote access to MCP tools scale?<a href="#ii-how-can-remote-access-to-mcp-tools-scale" class="hanchor" ariaLabel="Anchor">#</a> </h4>
<p>Currently, most MCP tools run on the same machines as the models which use them. Remote MCP servers will become more and more important in the future. They will prevent users from having to set up MCP servers for every model and every project in which they want to use them. They will also enable multi-agent functionality that isn’t widely available today, like being able to share context and facilitate communication among multiple models.</p>
<p>Current transports for MCP introduce heavy latency to the user experience. What technologies will allow MCP tools to serve low latency and high throughput interactions?</p>
<h4 id="iii-should-mcp-be-requestresponse-or-something-else">III. Should MCP be request/response, or something else?<a href="#iii-should-mcp-be-requestresponse-or-something-else" class="hanchor" ariaLabel="Anchor">#</a> </h4>
<p>The current Model Context Protocol <em><code>StreamableHTTP</code></em> specification is ambiguous on whether there can be multiple responses per MCP request, and how such responses should be handled by the clients. This is fair, as this introduces a lot of complexity.</p>
<p>However, if we want context to change dynamically in response to real-world conditions, or if we want models to be able to modify the context of other models proactively, this is exactly the kind of behavior that will need to be specified.</p>
<h4 id="iv-how-are-mcp-exposed-tools-discovered-by-models">IV. How are MCP-exposed tools discovered by models?<a href="#iv-how-are-mcp-exposed-tools-discovered-by-models" class="hanchor" ariaLabel="Anchor">#</a> </h4>
<p>Is general-purpose search (e.g. Bing, Google, Brave) sufficient for models to discover useful tools? Or does there need to be an MCP-specific registry/search engine?</p>
<p>If an MCP-specific search engine is required, who curates or indexes the tool ecosystem—models, users, third parties, or an open protocol?</p>
<h4 id="v-how-should-context-be-composed-across-many-tools-without-exceeding-model-limits">V. How should context be composed across many tools without exceeding model limits?<a href="#v-how-should-context-be-composed-across-many-tools-without-exceeding-model-limits" class="hanchor" ariaLabel="Anchor">#</a> </h4>
<p>What abstractions allow prioritization, summarization, or selective inclusion of tool state? Can models learn to query tool context selectively and iteratively rather than consuming it all up front? How do we manage structured, heterogeneous, and dynamic context under a fixed token budget?</p>
<h3 id="guidelines">Guidelines<a href="#guidelines" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>If you&rsquo;re building, here are some useful guidelines:</p>
<h4 id="tool-surfaces-not-apps">Tool surfaces, not apps<a href="#tool-surfaces-not-apps" class="hanchor" ariaLabel="Anchor">#</a> </h4>
<p>Build for invocation, not interaction. Instead of full-stack products, create tools that models can learn to use. Think APIs that describe their own affordances, state machines that expose their shape to LLMs, or real-world systems that accept high-level intents.</p>
<h4 id="shared-execution-layers">Shared execution layers<a href="#shared-execution-layers" class="hanchor" ariaLabel="Anchor">#</a> </h4>
<p>As MCP adoption grows, we’ll need shared environments where models can operate across tools and coordinate across agents. Low-latency, high-throughput servers that handle model-initiated actions will be a key battleground.</p>
<h4 id="model-native-ux-primitives">Model-native UX primitives<a href="#model-native-ux-primitives" class="hanchor" ariaLabel="Anchor">#</a> </h4>
<p>Forget screens and buttons. What does undo look like when the user is a model? What does a loading spinner mean in a multi-agent context? There’s a new UX stack to invent—one where models are the users and humans are co-pilots.</p>
<h4 id="defensibility-through-context-not-ui">Defensibility through context, not UI<a href="#defensibility-through-context-not-ui" class="hanchor" ariaLabel="Anchor">#</a> </h4>
<p>In this new world, UI is transient. Context is persistent. Products that own proprietary context—data, workflows, structured environments—will define the next defensible layer. This is the new terrain for moats.</p>
<p><strong>Remember: The UI is no longer the product. The model is. And the model needs a world it can operate.</strong></p>

      </div></div>

  
    

  

  
    

  
</article>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2025 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      </div>
  </div>
</footer>






<script type="text/javascript" src="/blog/bundle.min.js"></script>





  
</div>

</body>
</html>
